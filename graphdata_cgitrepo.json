{
  "nodes": [
    {
      "id": 0,
      "name": "jsanalysis.go",
      "category": "file",
      "path": "cgitrepo/goservice/jsanalysis.go",
      "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"net\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/sourcegraph/jsonrpc2\"\n)\n\n// CallDetail holds details about a function call.\ntype CallDetail struct {\n\tName string `json:\"name\"`\n\tLine int    `json:\"line\"`\n}\n\n// Transformation holds information about a variable re-assignment.\ntype Transformation struct {\n\tFile string `json:\"file\"`\n\tLine int    `json:\"line\"`\n}\n\n// FunctionSymbol holds information about a function.\ntype FunctionSymbol struct {\n\tName      string       `json:\"name\"`\n\tStartLine int          `json:\"start_line\"`\n\tEndLine   int          `json:\"end_line\"`\n\tCalls     []CallDetail `json:\"calls\"`\n}\n\n// VariableSymbol holds variable information, its transformations, and its usage (which may be nested).\ntype VariableSymbol struct {\n\tName            string           `json:\"name\"`\n\tDefinedAtLine   int              `json:\"defined_at_line\"`\n\tTransformations []Transformation `json:\"transformations\"`\n\t// Ordered usage locations (file:line) tracking\n\tUsedInFiles []string `json:\"used_in_files\"`\n}\n\n// JSAnalysisReport holds the analysis report for a single JS file.\ntype JSAnalysisReport struct {\n\tFile      string           `json:\"file\"`\n\tFunctions []FunctionSymbol `json:\"functions\"`\n\tVariables []VariableSymbol `json:\"variables\"`\n}\n\n// -----------------------\n// LSP Integration Helpers\n// -----------------------\n\n// lspRequest sends an LSP call using the provided connection.\nfunc lspRequest(ctx context.Context, conn *jsonrpc2.Conn, method string, params interface{}, result interface{}) error {\n\treturn conn.Call(ctx, method, params, result)\n}\n\n// FindVariableReferencesLSP determines the references for a variable (given its file, line and character)\n// by calling the \"textDocument/references\" method. Note that the LSP server must support this.\nfunc FindVariableReferencesLSP(ctx context.Context, conn *jsonrpc2.Conn, file string, line, character int) ([]string, error) {\n\t// Prepare the reference parameters per LSP spec.\n\tparams := map[string]interface{}{\n\t\t\"textDocument\": map[string]interface{}{\n\t\t\t\"uri\": file,\n\t\t},\n\t\t\"position\": map[string]interface{}{\n\t\t\t\"line\":      line,\n\t\t\t\"character\": character,\n\t\t},\n\t\t\"context\": map[string]interface{}{\n\t\t\t\"includeDeclaration\": true,\n\t\t},\n\t}\n\tvar refs []struct {\n\t\tUri   string `json:\"uri\"`\n\t\tRange struct {\n\t\t\tStart struct {\n\t\t\t\tLine      int `json:\"line\"`\n\t\t\t\tCharacter int `json:\"character\"`\n\t\t\t} `json:\"start\"`\n\t\t} `json:\"range\"`\n\t}\n\tif err := lspRequest(ctx, conn, \"textDocument/references\", params, \u0026refs); err != nil {\n\t\treturn nil, err\n\t}\n\tvar locations []string\n\tfor _, ref := range refs {\n\t\t// Format each reference as \"filepath:line\".\n\t\tlocations = append(locations, fmt.Sprintf(\"%s:%d\", ref.Uri, ref.Range.Start.Line+1))\n\t}\n\treturn locations, nil\n}\n\n// -----------------------\n// File analysis functions\n// -----------------------\n\n// AnalyzeJSFileLSP uses LSP integration to analyze a JavaScript file fully.\n// It requests both document symbols and variable references so that each variable’s\n// UsedInFiles field is populated with the ordered usage paths across the repo.\nfunc AnalyzeJSFileLSP(filePath string) (*JSAnalysisReport, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), 15*time.Second)\n\tdefer cancel()\n\n\t// Connect to the LSP server.\n\tnetConn, err := net.Dial(\"tcp\", \"localhost:2087\")\n\tif err != nil {\n\t\t// Fallback to our internal analysis if LSP is not available.\n\t\treturn AnalyzeJSFile(filePath)\n\t}\n\n\tstream := jsonrpc2.NewBufferedStream(netConn, jsonrpc2.VSCodeObjectCodec{})\n\tconn := jsonrpc2.NewConn(ctx, stream, jsonrpc2.HandlerWithError(func(ctx context.Context, conn *jsonrpc2.Conn, req *jsonrpc2.Request) (interface{}, error) {\n\t\treturn nil, nil\n\t}))\n\tdefer conn.Close()\n\n\t// 1. Initialize LSP handshake.\n\tinitParams := map[string]interface{}{\n\t\t\"processId\":    os.Getpid(),\n\t\t\"rootUri\":      fmt.Sprintf(\"file://%s\", RepoDir),\n\t\t\"capabilities\": map[string]interface{}{},\n\t}\n\tvar initResult interface{}\n\tif err := conn.Call(ctx, \"initialize\", initParams, \u0026initResult); err != nil {\n\t\treturn AnalyzeJSFile(filePath)\n\t}\n\tconn.Notify(ctx, \"initialized\", struct{}{})\n\n\t// 2. Open the document.\n\tcontent, err := os.ReadFile(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdidOpen := map[string]interface{}{\n\t\t\"textDocument\": map[string]interface{}{\n\t\t\t\"uri\":        filePath,\n\t\t\t\"languageId\": \"javascript\",\n\t\t\t\"version\":    1,\n\t\t\t\"text\":       string(content),\n\t\t},\n\t}\n\tconn.Notify(ctx, \"textDocument/didOpen\", didOpen)\n\n\t// 3. Request document symbols.\n\tsymbolParams := map[string]interface{}{\n\t\t\"textDocument\": map[string]interface{}{\n\t\t\t\"uri\": filePath,\n\t\t},\n\t}\n\tvar symbols []interface{}\n\tif err := conn.Call(ctx, \"textDocument/documentSymbol\", symbolParams, \u0026symbols); err != nil {\n\t\t// Fallback if there is an error.\n\t\treturn AnalyzeJSFile(filePath)\n\t}\n\n\t// Now do a basic internal analysis to capture variable definitions.\n\tlines := regexp.MustCompile(\"\\r?\\n\").Split(string(content), -1)\n\treVar := regexp.MustCompile(`(var|let|const)\\s+(\\w+)`)\n\n\tvar variables []VariableSymbol\n\n\t// For each variable declaration, use LSP references to get its usage.\n\tfor i, line := range lines {\n\t\tif matches := reVar.FindStringSubmatch(line); matches != nil {\n\t\t\tvname := matches[2]\n\n\t\t\t// Find the column (naively using indexOf)\n\t\t\tcol := strings.Index(line, vname)\n\t\t\tusageList, err := FindVariableReferencesLSP(ctx, conn, filePath, i, col)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Error finding references for variable %s in %s:%d: %v\", vname, filePath, i+1, err)\n\t\t\t}\n\t\t\ttransforms := extractVariableTransformations(filePath, vname, lines)\n\t\t\tvariables = append(variables, VariableSymbol{\n\t\t\t\tName:            vname,\n\t\t\t\tDefinedAtLine:   i + 1,\n\t\t\t\tTransformations: transforms,\n\t\t\t\tUsedInFiles:     usageList,\n\t\t\t})\n\t\t}\n\t}\n\n\t// For functions, we map document symbols (assumed to be functions) into our structure.\n\tfunctions := mapSymbolsToFunctions(symbols)\n\n\treport := \u0026JSAnalysisReport{\n\t\tFile:      filePath,\n\t\tFunctions: functions,\n\t\tVariables: variables,\n\t}\n\n\t// Optional: Shutdown LSP connection gracefully.\n\tvar shutdownResult interface{}\n\t_ = conn.Call(ctx, \"shutdown\", nil, \u0026shutdownResult)\n\tconn.Notify(ctx, \"exit\", nil)\n\n\treport.File += \" (analyzed by LSP)\"\n\treturn report, nil\n}\n\n// AnalyzeJSFile is our fallback analysis (using regex scanning) if LSP isn’t available.\nfunc AnalyzeJSFile(filePath string) (*JSAnalysisReport, error) {\n\tcontent, err := os.ReadFile(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlines := regexp.MustCompile(\"\\r?\\n\").Split(string(content), -1)\n\n\treFunc := regexp.MustCompile(`function\\s+(\\w+)\\s*\\(`)\n\tuserDefined := make(map[string]bool)\n\tfor _, line := range lines {\n\t\tif matches := reFunc.FindStringSubmatch(line); matches != nil {\n\t\t\tuserDefined[matches[1]] = true\n\t\t}\n\t}\n\n\tvar functions []FunctionSymbol\n\tvar variables []VariableSymbol\n\treVar := regexp.MustCompile(`(var|let|const)\\s+(\\w+)`)\n\n\tfor i, line := range lines {\n\t\tif matches := reFunc.FindStringSubmatch(line); matches != nil {\n\t\t\tfname := matches[1]\n\t\t\tfunctions = append(functions, FunctionSymbol{\n\t\t\t\tName:      fname,\n\t\t\t\tStartLine: i + 1,\n\t\t\t\tEndLine:   i + 1, // placeholder\n\t\t\t\tCalls:     extractFunctionCalls(userDefined, fname, lines),\n\t\t\t})\n\t\t}\n\t\tif matches := reVar.FindStringSubmatch(line); matches != nil {\n\t\t\tvname := matches[2]\n\t\t\tusageList, err := FindVariableUsageAcrossRepo(vname)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Error finding usage for variable %s: %v\", vname, err)\n\t\t\t}\n\t\t\tvariables = append(variables, VariableSymbol{\n\t\t\t\tName:            vname,\n\t\t\t\tDefinedAtLine:   i + 1,\n\t\t\t\tTransformations: extractVariableTransformations(filePath, vname, lines),\n\t\t\t\tUsedInFiles:     usageList,\n\t\t\t})\n\t\t}\n\t}\n\n\treport := \u0026JSAnalysisReport{\n\t\tFile:      filePath,\n\t\tFunctions: functions,\n\t\tVariables: variables,\n\t}\n\treturn report, nil\n}\n\n// extractFunctionCalls scans the file lines to extract call details from user-defined functions.\nfunc extractFunctionCalls(userDefined map[string]bool, currentFunc string, lines []string) []CallDetail {\n\tvar calls []CallDetail\n\treCall := regexp.MustCompile(`(\\w+)\\s*\\(`)\n\tfor i, line := range lines {\n\t\tmatches := reCall.FindAllStringSubmatch(line, -1)\n\t\tfor _, m := range matches {\n\t\t\tcallName := m[1]\n\t\t\tif callName == currentFunc {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif _, exists := userDefined[callName]; !exists {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcalls = append(calls, CallDetail{\n\t\t\t\tName: callName,\n\t\t\t\tLine: i + 1,\n\t\t\t})\n\t\t}\n\t}\n\treturn calls\n}\n\n// extractVariableTransformations locates where a variable is re-assigned.\nfunc extractVariableTransformations(filePath, varName string, lines []string) []Transformation {\n\tvar transforms []Transformation\n\treAssign := regexp.MustCompile(fmt.Sprintf(`\\b%s\\s*=`, regexp.QuoteMeta(varName)))\n\tfor i, line := range lines {\n\t\tif reAssign.MatchString(line) {\n\t\t\ttransforms = append(transforms, Transformation{\n\t\t\t\tFile: filePath,\n\t\t\t\tLine: i + 1,\n\t\t\t})\n\t\t}\n\t}\n\treturn transforms\n}\n\n// FindVariableUsageAcrossRepo scans all JS, JSX, TS, and TSX files under RepoDir\n// using a simple regex and returns matching usage locations.\nfunc FindVariableUsageAcrossRepo(varName string) ([]string, error) {\n\tvar usages []string\n\tpattern := fmt.Sprintf(`\\b%s\\b`, regexp.QuoteMeta(varName))\n\treUsage := regexp.MustCompile(pattern)\n\n\terr := filepath.Walk(RepoDir, func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Error accessing %s: %v\", path, err)\n\t\t\treturn nil\n\t\t}\n\t\tif info.IsDir() {\n\t\t\treturn nil\n\t\t}\n\t\t// Consider only JavaScript-related files.\n\t\tif !(strings.HasSuffix(path, \".js\") ||\n\t\t\tstrings.HasSuffix(path, \".jsx\") ||\n\t\t\tstrings.HasSuffix(path, \".ts\") ||\n\t\t\tstrings.HasSuffix(path, \".tsx\")) {\n\t\t\treturn nil\n\t\t}\n\t\tcontent, err := os.ReadFile(path)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Error reading %s: %v\", path, err)\n\t\t\treturn nil\n\t\t}\n\t\tlines := regexp.MustCompile(\"\\r?\\n\").Split(string(content), -1)\n\t\tfor i, line := range lines {\n\t\t\tif reUsage.MatchString(line) {\n\t\t\t\tusages = append(usages, fmt.Sprintf(\"%s:%d\", path, i+1))\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\treturn usages, err\n}\n\n// mapSymbolsToFunctions converts LSP document symbols into our FunctionSymbol structure.\nfunc mapSymbolsToFunctions(symbols []interface{}) []FunctionSymbol {\n\tvar functions []FunctionSymbol\n\tfor _, symItem := range symbols {\n\t\tif sym, ok := symItem.(map[string]interface{}); ok {\n\t\t\tname, _ := sym[\"name\"].(string)\n\t\t\tstartLine, endLine := extractRange(sym)\n\t\t\tfunctions = append(functions, FunctionSymbol{\n\t\t\t\tName:      name,\n\t\t\t\tStartLine: startLine,\n\t\t\t\tEndLine:   endLine,\n\t\t\t\tCalls:     []CallDetail{},\n\t\t\t})\n\t\t}\n\t}\n\treturn functions\n}\n\n// extractRange extracts start and end lines from an LSP symbol.\nfunc extractRange(sym map[string]interface{}) (int, int) {\n\tif r, ok := sym[\"range\"].(map[string]interface{}); ok {\n\t\tif start, ok := r[\"start\"].(map[string]interface{}); ok {\n\t\t\tif end, ok := r[\"end\"].(map[string]interface{}); ok {\n\t\t\t\tstartLine, _ := start[\"line\"].(float64)\n\t\t\t\tendLine, _ := end[\"line\"].(float64)\n\t\t\t\treturn int(startLine) + 1, int(endLine) + 1\n\t\t\t}\n\t\t}\n\t}\n\treturn 0, 0\n}\n\n// SaveJSAnalysisReports writes the aggregated analysis reports to a JSON file.\nfunc SaveJSAnalysisReports(reports []JSAnalysisReport, outputPath string) error {\n\tdata, err := json.MarshalIndent(reports, \"\", \"  \")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn os.WriteFile(outputPath, data, 0644)\n}\n",
      "dependencies": [
        "encoding/json",
        "log",
        "os",
        "regexp",
        "time",
        "github.com/sourcegraph/jsonrpc2",
        "context"
      ]
    },
    {
      "id": 1,
      "name": "main.go",
      "category": "file",
      "path": "cgitrepo/goservice/main.go",
      "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n)\n\n// Global repo directory\nvar RepoDir string\n\nfunc main() {\n\tif len(os.Args) \u003c 2 {\n\t\tfmt.Println(\"Usage: graphdata \u003crepo-directory\u003e\")\n\t\tos.Exit(1)\n\t}\n\trepoDir := os.Args[1]\n\tRepoDir = repoDir\n\n\t// Detect languages used in the repository.\n\tlanguages, err := DetectLanguages(repoDir)\n\tif err != nil {\n\t\tlog.Fatalf(\"Error detecting languages: %v\", err)\n\t}\n\tfmt.Printf(\"Detected languages: %v\\n\", languages)\n\n\t// Determine the main language.\n\tmainLanguage := \"unknown\"\n\tif len(languages) \u003e 0 {\n\t\tmainLanguage = languages[0] // Assuming the first detected language is the main one\n\t}\n\n\t// Find entry points based on the detected languages.\n\tfiles, err := FindEntryPoints(repoDir, languages)\n\tif err != nil {\n\t\tlog.Fatalf(\"Error scanning directory: %v\", err)\n\t}\n\tif len(files) == 0 {\n\t\tlog.Fatal(\"No entry point files found in the provided directory.\")\n\t}\n\n\t// Check for Prisma schema file.\n\tprismaSchemaPath := \"\"\n\terr = filepath.Walk(repoDir, func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !info.IsDir() \u0026\u0026 filepath.Base(path) == \"schema.prisma\" {\n\t\t\tprismaSchemaPath = path\n\t\t\treturn filepath.SkipDir // Stop after finding the first schema.prisma\n\t\t}\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tlog.Printf(\"Error while searching for Prisma schema: %v\", err)\n\t}\n\tif prismaSchemaPath != \"\" {\n\t\tfmt.Println(\"Found Prisma schema at:\", prismaSchemaPath)\n\t\t// Add the Prisma schema to our files list.\n\t\tfiles = append(files, prismaSchemaPath)\n\t}\n\n\t// Read package.json dependencies if JavaScript is detected.\n\tvar pkgDeps map[string]bool\n\tjsDetected := contains(languages, \"javascript\") ||\n\t\tcontains(languages, \"typescript\") ||\n\t\tcontains(languages, \"jsx\") ||\n\t\tcontains(languages, \"tsx\")\n\n\tif jsDetected {\n\t\tpkgDeps, err = ReadPackageJSON(repoDir)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Warning: could not parse package.json: %v\", err)\n\t\t}\n\t}\n\n\t// Build a dependency tree by scanning each file.\n\tdepTree := make(map[string][]string)\n\t// Accumulate analysis reports.\n\tvar jsReports []JSAnalysisReport\n\tvar goReports []GoAnalysisReport\n\tvar pyReports []PythonAnalysisReport\n\t// Track if we found a Prisma schema for inclusion in the graph.\n\tvar prismaSchema *PrismaSchema\n\n\tfor _, file := range files {\n\t\t// Use the ScanDependencies function from dependency_scanner.go.\n\t\tdeps, err := ScanDependencies(file)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Error scanning %s: %v\", file, err)\n\t\t\tcontinue\n\t\t}\n\t\tdepTree[file] = deps\n\t\t// Optionally check import/export specifics.\n\t\tCheckImportsExports(file, languageForFile(file))\n\n\t\t// Within the file scanning loop:\n\t\tfileLanguage := languageForFile(file)\n\t\tif fileLanguage == \"javascript\" || fileLanguage == \"typescript\" ||\n\t\t\tfileLanguage == \"jsx\" || fileLanguage == \"tsx\" {\n\t\t\treport, err := AnalyzeJSFileLSP(file)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Error analyzing JS file %s: %v\", file, err)\n\t\t\t} else {\n\t\t\t\tjsReports = append(jsReports, *report)\n\t\t\t}\n\t\t} else if fileLanguage == \"go\" {\n\t\t\treport, err := AnalyzeGoFileLSP(file)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Error analyzing Go file %s: %v\", file, err)\n\t\t\t} else {\n\t\t\t\tgoReports = append(goReports, *report)\n\t\t\t}\n\t\t} else if fileLanguage == \"python\" {\n\t\t\treport, err := AnalyzePythonFileLSP(file)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Error analyzing Python file %s: %v\", file, err)\n\t\t\t} else {\n\t\t\t\tpyReports = append(pyReports, *report)\n\t\t\t}\n\t\t} else if fileLanguage == \"prisma\" {\n\t\t\t// Read and parse Prisma schema.\n\t\t\tschema, err := ParsePrismaSchema(file)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Error parsing Prisma schema %s: %v\", file, err)\n\t\t\t} else {\n\t\t\t\tprismaSchema = schema\n\t\t\t}\n\t\t}\n\t}\n\n\t// Build the dependency graph.\n\tgraph, err := buildGraphWrapper(depTree, pkgDeps, mainLanguage, prismaSchema)\n\tif err != nil {\n\t\tlog.Fatalf(\"Error building graph: %v\", err)\n\t}\n\n\t// Save the dependency graph as JSON.\n\terr = SaveGraphData(\"graphdata.json\", graph)\n\tif err != nil {\n\t\tlog.Fatalf(\"Error writing graph data: %v\", err)\n\t}\n\tfmt.Println(\"Graph data saved to graphdata.json\")\n\n\t// Save the aggregated analysis reports.\n\tif jsDetected \u0026\u0026 len(jsReports) \u003e 0 {\n\t\terr = SaveJSAnalysisReports(jsReports, \"analysis_data.json\")\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"Error writing JS analysis data: %v\", err)\n\t\t}\n\t\tfmt.Println(\"JS analysis data saved to analysis_data.json\")\n\t}\n\tif len(goReports) \u003e 0 {\n\t\terr = SaveGoAnalysisReports(goReports, \"analysis_data.json\")\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"Error writing Go analysis data: %v\", err)\n\t\t}\n\t\tfmt.Println(\"Go analysis data saved to analysis_data.json\")\n\t}\n\tif len(pyReports) \u003e 0 {\n\t\terr = SavePyAnalysisReports(pyReports, \"analysis_data.json\")\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"Error writing Python analysis data: %v\", err)\n\t\t}\n\t\tfmt.Println(\"Python analysis data saved to analysis_data.json\")\n\t}\n}\n\nfunc contains(slice []string, str string) bool {\n\tfor _, s := range slice {\n\t\tif s == str {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc languageForFile(file string) string {\n\tif hasSuffix(file, \".js\") || hasSuffix(file, \".ts\") || hasSuffix(file, \".jsx\") || hasSuffix(file, \".tsx\") {\n\t\treturn \"javascript\"\n\t} else if hasSuffix(file, \".py\") {\n\t\treturn \"python\"\n\t} else if hasSuffix(file, \".go\") {\n\t\treturn \"go\"\n\t} else if filepath.Base(file) == \"schema.prisma\" {\n\t\treturn \"prisma\"\n\t}\n\treturn \"unknown\"\n}\n\n// buildGraphWrapper should remain as a thin wrapper to call BuildGraph from graph_builder.go.\nfunc buildGraphWrapper(depTree map[string][]string, pkgDeps map[string]bool, mainLang string, prismaSchema *PrismaSchema) (GraphData, error) {\n\treturn BuildGraph(depTree, pkgDeps, mainLang, prismaSchema)\n}\n",
      "dependencies": [
        "path/filepath",
        "fmt",
        "log"
      ]
    },
    {
      "id": 2,
      "name": "packagejson.go",
      "category": "file",
      "path": "cgitrepo/goservice/packagejson.go",
      "content": "package main\n\nimport (\n\t\"encoding/json\"\n\t\"os\"\n\t\"path/filepath\"\n)\n\ntype PackageJSON struct {\n\tDependencies    map[string]string `json:\"dependencies\"`\n\tDevDependencies map[string]string `json:\"devDependencies\"`\n}\n\n// ReadPackageJSON reads and parses package.json and returns a map of dependency names.\nfunc ReadPackageJSON(repoDir string) (map[string]bool, error) {\n\tpkgPath := filepath.Join(repoDir, \"package.json\")\n\tcontent, err := os.ReadFile(pkgPath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar pkg PackageJSON\n\terr = json.Unmarshal(content, \u0026pkg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdeps := make(map[string]bool)\n\tfor dep := range pkg.Dependencies {\n\t\tdeps[dep] = true\n\t}\n\tfor dep := range pkg.DevDependencies {\n\t\tdeps[dep] = true\n\t}\n\n\treturn deps, nil\n}\n",
      "dependencies": [
        "encoding/json",
        "os",
        "path/filepath"
      ]
    },
    {
      "id": 3,
      "name": "prisma.go",
      "category": "file",
      "path": "cgitrepo/goservice/prisma.go",
      "content": "package main\n\nimport (\n\t\"bufio\"\n\t\"os\"\n\t\"strings\"\n)\n\n// PrismaModel represents a model in the Prisma schema\ntype PrismaModel struct {\n\tName      string            `json:\"name\"`\n\tFields    map[string]string `json:\"fields\"` // Field name -\u003e type\n\tRelations []struct {\n\t\tField        string `json:\"field\"`\n\t\tRelatedModel string `json:\"relatedModel\"`\n\t\tType         string `json:\"type\"` // e.g., \"one-to-many\", \"many-to-one\"\n\t} `json:\"relations\"`\n}\n\n// PrismaSchema represents the entire schema structure\ntype PrismaSchema struct {\n\tFilePath string        `json:\"filePath\"`\n\tModels   []PrismaModel `json:\"models\"`\n}\n\n// ParsePrismaSchema reads a Prisma schema file and extracts model information\nfunc ParsePrismaSchema(filePath string) (*PrismaSchema, error) {\n\tfile, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer file.Close()\n\n\tschema := \u0026PrismaSchema{\n\t\tFilePath: filePath,\n\t\tModels:   []PrismaModel{},\n\t}\n\n\tscanner := bufio.NewScanner(file)\n\tvar currentModel *PrismaModel\n\tinModel := false\n\n\tfor scanner.Scan() {\n\t\tline := strings.TrimSpace(scanner.Text())\n\n\t\t// Skip empty lines and comments\n\t\tif line == \"\" || strings.HasPrefix(line, \"//\") {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Check for model definition\n\t\tif strings.HasPrefix(line, \"model \") {\n\t\t\tinModel = true\n\t\t\tmodelName := strings.TrimPrefix(line, \"model \")\n\t\t\tmodelName = strings.TrimSuffix(modelName, \" {\")\n\t\t\tcurrentModel = \u0026PrismaModel{\n\t\t\t\tName:   modelName,\n\t\t\t\tFields: make(map[string]string),\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// Check for end of model\n\t\tif inModel \u0026\u0026 line == \"}\" {\n\t\t\tschema.Models = append(schema.Models, *currentModel)\n\t\t\tinModel = false\n\t\t\tcurrentModel = nil\n\t\t\tcontinue\n\t\t}\n\n\t\t// Parse field definitions within a model\n\t\tif inModel \u0026\u0026 currentModel != nil {\n\t\t\t// Skip relation fields or other complex definitions for simplicity\n\t\t\tif !strings.Contains(line, \"//\") \u0026\u0026 strings.Contains(line, \" \") {\n\t\t\t\tparts := strings.SplitN(line, \" \", 2)\n\t\t\t\tif len(parts) == 2 {\n\t\t\t\t\tfieldName := parts[0]\n\t\t\t\t\tfieldType := strings.Split(parts[1], \" \")[0] // Get just the type without attributes\n\t\t\t\t\tcurrentModel.Fields[fieldName] = fieldType\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// While parsing fields, also look for relations\n\t\t\tif strings.Contains(line, \"@relation\") {\n\t\t\t\t// Extract relation information\n\t\t\t\tfieldName := strings.Split(line, \" \")[0]\n\t\t\t\trelatedModel := \"\"\n\n\t\t\t\t// Extract the related model name - simplistic parsing\n\t\t\t\tif strings.Contains(line, \"references: [\") {\n\t\t\t\t\tparts := strings.Split(line, \"references: [\")\n\t\t\t\t\tif len(parts) \u003e 1 {\n\t\t\t\t\t\trefParts := strings.Split(parts[1], \"]\")\n\t\t\t\t\t\tif len(refParts) \u003e 0 {\n\t\t\t\t\t\t\trelatedModel = strings.TrimSpace(refParts[0])\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Add this relation to the model\n\t\t\t\tif relatedModel != \"\" {\n\t\t\t\t\trelation := struct {\n\t\t\t\t\t\tField        string `json:\"field\"`\n\t\t\t\t\t\tRelatedModel string `json:\"relatedModel\"`\n\t\t\t\t\t\tType         string `json:\"type\"`\n\t\t\t\t\t}{\n\t\t\t\t\t\tField:        fieldName,\n\t\t\t\t\t\tRelatedModel: relatedModel,\n\t\t\t\t\t\tType:         \"relation\", // A more sophisticated parser would determine the exact type\n\t\t\t\t\t}\n\n\t\t\t\t\t// Append to Relations slice\n\t\t\t\t\tcurrentModel.Relations = append(currentModel.Relations, relation)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := scanner.Err(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn schema, nil\n}\n",
      "dependencies": [
        "bufio",
        "os",
        "strings"
      ]
    },
    {
      "id": 4,
      "name": "python_scanner.go",
      "category": "file",
      "path": "cgitrepo/goservice/python_scanner.go",
      "content": "package main\n\nimport (\n    \"os\"\n    \"regexp\"\n)\n\n// ScanPythonScanner scans a Python file for dependency strings (imports).\nfunc ScanPythonScanner(filePath string) ([]string, error) {\n    content, err := os.ReadFile(filePath)\n    if err != nil {\n        return nil, err\n\t}\n    text := string(content)\n\n    // Match patterns like \"import module\" and \"from module import ...\"\n    reImport := regexp.MustCompile(`(?m)^(?:import|from)\\s+([\\w\\.]+)`)\n    depMap := make(map[string]bool)\n    for _, m := range reImport.FindAllStringSubmatch(text, -1) {\n        depMap[m[1]] = true\n    }\n    var deps []string\n    for dep := range depMap {\n        deps = append(deps, dep)\n    }\n    return deps, nil\n}",
      "dependencies": [
        "os",
        "regexp"
      ]
    },
    {
      "id": 5,
      "name": "dependency_scanner.go",
      "category": "file",
      "path": "cgitrepo/goservice/dependency_scanner.go",
      "content": "package main\n\nimport (\n\t\"errors\"\n\t\"path/filepath\"\n)\n\n// ScanDependencies chooses the appropriate scanner based on the file extension.\nfunc ScanDependencies(filePath string) ([]string, error) {\n\t// Skip scanning for Prisma schema files. They are handled separately.\n\tif filepath.Base(filePath) == \"schema.prisma\" {\n\t\treturn []string{}, nil\n\t}\n\n\tif hasSuffix(filePath, \".js\") ||\n\t\thasSuffix(filePath, \".ts\") ||\n\t\thasSuffix(filePath, \".jsx\") ||\n\t\thasSuffix(filePath, \".tsx\") {\n\t\treturn ScanJSScanner(filePath)\n\t} else if hasSuffix(filePath, \".py\") {\n\t\treturn ScanPythonScanner(filePath)\n\t} else if hasSuffix(filePath, \".go\") {\n\t\treturn ScanGoScanner(filePath)\n\t}\n\treturn nil, errors.New(\"unsupported file type for dependency scanning\")\n}\n\n// hasSuffix is a helper function.\nfunc hasSuffix(path, suffix string) bool {\n\tl := len(suffix)\n\tif len(path) \u003c l {\n\t\treturn false\n\t}\n\treturn path[len(path)-l:] == suffix\n}\n",
      "dependencies": [
        "path/filepath",
        "errors"
      ]
    },
    {
      "id": 6,
      "name": "file_scanner.go",
      "category": "file",
      "path": "cgitrepo/goservice/file_scanner.go",
      "content": "package main\n\nimport (\n\t\"io/fs\"\n\t\"path/filepath\"\n\t\"strings\"\n)\n\n// Map of languages to their file extensions\nvar langExtensions = map[string][]string{\n\t\"javascript\": {\".js\", \".jsx\", \".ts\", \".tsx\"},\n\t\"python\":     {\".py\"},\n\t\"go\":         {\".go\"},\n}\n\n// FindEntryPoints walks through the repository and returns files that match known extensions.\nfunc FindEntryPoints(root string, languages []string) ([]string, error) {\n\tvar entryPoints []string\n\n\t// Build a flat list of extensions to search for.\n\tvar exts []string\n\tfor _, lang := range languages {\n\t\tif langExt, ok := langExtensions[lang]; ok {\n\t\t\texts = append(exts, langExt...)\n\t\t}\n\t}\n\n\terr := filepath.WalkDir(root, func(path string, d fs.DirEntry, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !d.IsDir() {\n\t\t\tfor _, ext := range exts {\n\t\t\t\tif strings.HasSuffix(path, ext) {\n\t\t\t\t\tentryPoints = append(entryPoints, path)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\treturn entryPoints, err\n}\n\n// DetectLanguages scans the repository and returns a list of detected languages.\nfunc DetectLanguages(root string) ([]string, error) {\n\tlangSet := make(map[string]bool)\n\terr := filepath.WalkDir(root, func(path string, d fs.DirEntry, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !d.IsDir() {\n\t\t\tif strings.HasSuffix(path, \".js\") || strings.HasSuffix(path, \".ts\") ||\n\t\t\t\tstrings.HasSuffix(path, \".jsx\") || strings.HasSuffix(path, \".tsx\") {\n\t\t\t\tlangSet[\"javascript\"] = true\n\t\t\t} else if strings.HasSuffix(path, \".py\") {\n\t\t\t\tlangSet[\"python\"] = true\n\t\t\t} else if strings.HasSuffix(path, \".go\") {\n\t\t\t\tlangSet[\"go\"] = true\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar languages []string\n\tfor lang := range langSet {\n\t\tlanguages = append(languages, lang)\n\t}\n\treturn languages, nil\n}\n",
      "dependencies": [
        "io/fs",
        "path/filepath",
        "strings"
      ]
    },
    {
      "id": 7,
      "name": "go\u0026pyanalysis.go",
      "category": "file",
      "path": "cgitrepo/goservice/go\u0026pyanalysis.go",
      "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"net\"\n\t\"os\"\n\t\"regexp\"\n\t\"time\"\n\n\t\"github.com/sourcegraph/jsonrpc2\"\n)\n\ntype GoFunctionSymbol struct {\n\tName      string       `json:\"name\"`\n\tStartLine int          `json:\"start_line\"`\n\tEndLine   int          `json:\"end_line\"`\n\tCalls     []CallDetail `json:\"calls\"`\n}\n\ntype GoVariableSymbol struct {\n\tName          string   `json:\"name\"`\n\tDefinedAtLine int      `json:\"defined_at_line\"`\n\tUsedInFiles   []string `json:\"used_in_files\"`\n}\n\ntype GoAnalysisReport struct {\n\tFile      string             `json:\"file\"`\n\tFunctions []GoFunctionSymbol `json:\"functions\"`\n\tVariables []GoVariableSymbol `json:\"variables\"`\n}\n\nfunc AnalyzeGoFileLSP(filePath string) (*GoAnalysisReport, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), 15*time.Second)\n\tdefer cancel()\n\n\t// Connect to the LSP server.\n\tnetConn, err := net.Dial(\"tcp\", \"localhost:2087\")\n\tif err != nil {\n\t\t// Fallback if LSP is not available.\n\t\treturn AnalyzeGoFile(filePath)\n\t}\n\n\tstream := jsonrpc2.NewBufferedStream(netConn, jsonrpc2.VSCodeObjectCodec{})\n\tconn := jsonrpc2.NewConn(ctx, stream, jsonrpc2.HandlerWithError(func(ctx context.Context, conn *jsonrpc2.Conn, req *jsonrpc2.Request) (interface{}, error) {\n\t\treturn nil, nil\n\t}))\n\tdefer conn.Close()\n\n\t// Initialize the LSP handshake.\n\tinitParams := map[string]interface{}{\n\t\t\"processId\":    os.Getpid(),\n\t\t\"rootUri\":      fmt.Sprintf(\"file://%s\", RepoDir),\n\t\t\"capabilities\": map[string]interface{}{},\n\t}\n\tvar initResult interface{}\n\tif err := conn.Call(ctx, \"initialize\", initParams, \u0026initResult); err != nil {\n\t\treturn AnalyzeGoFile(filePath)\n\t}\n\tconn.Notify(ctx, \"initialized\", struct{}{})\n\n\t// Open the document with languageId \"go\".\n\tcontent, err := os.ReadFile(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdidOpen := map[string]interface{}{\n\t\t\"textDocument\": map[string]interface{}{\n\t\t\t\"uri\":        filePath,\n\t\t\t\"languageId\": \"go\",\n\t\t\t\"version\":    1,\n\t\t\t\"text\":       string(content),\n\t\t},\n\t}\n\tconn.Notify(ctx, \"textDocument/didOpen\", didOpen)\n\n\t// Request document symbols.\n\tsymbolParams := map[string]interface{}{\n\t\t\"textDocument\": map[string]interface{}{\n\t\t\t\"uri\": filePath,\n\t\t},\n\t}\n\tvar symbols []interface{}\n\tif err := conn.Call(ctx, \"textDocument/documentSymbol\", symbolParams, \u0026symbols); err != nil {\n\t\treturn AnalyzeGoFile(filePath)\n\t}\n\n\t// Basic fallback parsing for functions and variables.\n\tlines := regexp.MustCompile(\"\\r?\\n\").Split(string(content), -1)\n\t// For functions in Go: expecting lines starting with \"func\"\n\tregexp.MustCompile(`^func\\s+(\\w+)`)\n\t// For variable declarations, handle both \"var ...\" and short declarations \":=\"\n\treVar := regexp.MustCompile(`\\b(var\\s+(\\w+)|(\\w+)\\s*:=)`)\n\n\tvar functions []GoFunctionSymbol\n\tvar variables []GoVariableSymbol\n\n\t// Map functions from LSP symbols.\n\tfor _, symItem := range symbols {\n\t\tif sym, ok := symItem.(map[string]interface{}); ok {\n\t\t\tname, _ := sym[\"name\"].(string)\n\t\t\tstartLine, endLine := extractRange(sym)\n\t\t\tfunctions = append(functions, GoFunctionSymbol{\n\t\t\t\tName:      name,\n\t\t\t\tStartLine: startLine,\n\t\t\t\tEndLine:   endLine,\n\t\t\t\tCalls:     []CallDetail{}, // advanced call extraction can be added here.\n\t\t\t})\n\t\t}\n\t}\n\n\t// Scan for variable declarations.\n\tfor i, line := range lines {\n\t\tif matches := reVar.FindStringSubmatch(line); matches != nil {\n\t\t\tvname := \"\"\n\t\t\tif matches[2] != \"\" {\n\t\t\t\tvname = matches[2]\n\t\t\t} else if matches[3] != \"\" {\n\t\t\t\tvname = matches[3]\n\t\t\t}\n\t\t\tif vname == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// Naively get usage locations (fallback across repo).\n\t\t\tusageList, err := FindVariableUsageAcrossRepo(vname)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Error finding usage for variable %s: %v\", vname, err)\n\t\t\t}\n\t\t\tvariables = append(variables, GoVariableSymbol{\n\t\t\t\tName:          vname,\n\t\t\t\tDefinedAtLine: i + 1,\n\t\t\t\tUsedInFiles:   usageList,\n\t\t\t})\n\t\t}\n\t}\n\n\treport := \u0026GoAnalysisReport{\n\t\tFile:      filePath,\n\t\tFunctions: functions,\n\t\tVariables: variables,\n\t}\n\treport.File += \" (Go analyzed by LSP)\"\n\treturn report, nil\n}\n\nfunc AnalyzeGoFile(filePath string) (*GoAnalysisReport, error) {\n\tcontent, err := os.ReadFile(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlines := regexp.MustCompile(\"\\r?\\n\").Split(string(content), -1)\n\treFunc := regexp.MustCompile(`^func\\s+(\\w+)`)\n\treVar := regexp.MustCompile(`\\b(var\\s+(\\w+)|(\\w+)\\s*:=)`)\n\n\tvar functions []GoFunctionSymbol\n\tvar variables []GoVariableSymbol\n\n\tfor i, line := range lines {\n\t\tif matches := reFunc.FindStringSubmatch(line); matches != nil {\n\t\t\tfunctions = append(functions, GoFunctionSymbol{\n\t\t\t\tName:      matches[1],\n\t\t\t\tStartLine: i + 1,\n\t\t\t\tEndLine:   i + 1, // placeholder for end line.\n\t\t\t\tCalls:     []CallDetail{},\n\t\t\t})\n\t\t}\n\t\tif matches := reVar.FindStringSubmatch(line); matches != nil {\n\t\t\tvname := \"\"\n\t\t\tif matches[2] != \"\" {\n\t\t\t\tvname = matches[2]\n\t\t\t} else if matches[3] != \"\" {\n\t\t\t\tvname = matches[3]\n\t\t\t}\n\t\t\tif vname == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tusageList, err := FindVariableUsageAcrossRepo(vname)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Error finding usage for variable %s: %v\", vname, err)\n\t\t\t}\n\t\t\tvariables = append(variables, GoVariableSymbol{\n\t\t\t\tName:          vname,\n\t\t\t\tDefinedAtLine: i + 1,\n\t\t\t\tUsedInFiles:   usageList,\n\t\t\t})\n\t\t}\n\t}\n\n\treport := \u0026GoAnalysisReport{\n\t\tFile:      filePath,\n\t\tFunctions: functions,\n\t\tVariables: variables,\n\t}\n\treturn report, nil\n}\n\n// SaveGoAnalysisReports writes the Go analysis reports to a JSON file.\nfunc SaveGoAnalysisReports(reports []GoAnalysisReport, outputPath string) error {\n\tdata, err := json.MarshalIndent(reports, \"\", \"  \")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn os.WriteFile(outputPath, data, 0644)\n}\n\n// -----------------------\n// Advanced Python Analysis (LSP)\n// -----------------------\n\ntype PythonFunctionSymbol struct {\n\tName      string `json:\"name\"`\n\tStartLine int    `json:\"start_line\"`\n\tEndLine   int    `json:\"end_line\"`\n}\n\ntype PythonVariableSymbol struct {\n\tName          string `json:\"name\"`\n\tDefinedAtLine int    `json:\"defined_at_line\"`\n}\n\ntype PythonAnalysisReport struct {\n\tFile      string                 `json:\"file\"`\n\tFunctions []PythonFunctionSymbol `json:\"functions\"`\n\tVariables []PythonVariableSymbol `json:\"variables\"`\n}\n\nfunc AnalyzePythonFileLSP(filePath string) (*PythonAnalysisReport, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), 15*time.Second)\n\tdefer cancel()\n\n\t// Connect to the LSP server.\n\tnetConn, err := net.Dial(\"tcp\", \"localhost:2087\")\n\tif err != nil {\n\t\treturn AnalyzePythonFile(filePath)\n\t}\n\n\tstream := jsonrpc2.NewBufferedStream(netConn, jsonrpc2.VSCodeObjectCodec{})\n\tconn := jsonrpc2.NewConn(ctx, stream, jsonrpc2.HandlerWithError(func(ctx context.Context, conn *jsonrpc2.Conn, req *jsonrpc2.Request) (interface{}, error) {\n\t\treturn nil, nil\n\t}))\n\tdefer conn.Close()\n\n\t// Initialize LSP handshake.\n\tinitParams := map[string]interface{}{\n\t\t\"processId\":    os.Getpid(),\n\t\t\"rootUri\":      fmt.Sprintf(\"file://%s\", RepoDir),\n\t\t\"capabilities\": map[string]interface{}{},\n\t}\n\tvar initResult interface{}\n\tif err := conn.Call(ctx, \"initialize\", initParams, \u0026initResult); err != nil {\n\t\treturn AnalyzePythonFile(filePath)\n\t}\n\tconn.Notify(ctx, \"initialized\", struct{}{})\n\n\t// Open the document with languageId \"python\".\n\tcontent, err := os.ReadFile(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdidOpen := map[string]interface{}{\n\t\t\"textDocument\": map[string]interface{}{\n\t\t\t\"uri\":        filePath,\n\t\t\t\"languageId\": \"python\",\n\t\t\t\"version\":    1,\n\t\t\t\"text\":       string(content),\n\t\t},\n\t}\n\tconn.Notify(ctx, \"textDocument/didOpen\", didOpen)\n\n\t// Request document symbols.\n\tsymbolParams := map[string]interface{}{\n\t\t\"textDocument\": map[string]interface{}{\n\t\t\t\"uri\": filePath,\n\t\t},\n\t}\n\tvar symbols []interface{}\n\tif err := conn.Call(ctx, \"textDocument/documentSymbol\", symbolParams, \u0026symbols); err != nil {\n\t\treturn AnalyzePythonFile(filePath)\n\t}\n\n\t// Basic internal analysis.\n\tlines := regexp.MustCompile(\"\\r?\\n\").Split(string(content), -1)\n\t// For functions in Python.\n\tregexp.MustCompile(`^def\\s+(\\w+)\\s*\\(`)\n\t// For variable assignments; this is a naive approach.\n\treVar := regexp.MustCompile(`^(\\w+)\\s*=`)\n\tvar functions []PythonFunctionSymbol\n\tvar variables []PythonVariableSymbol\n\n\tfor _, symItem := range symbols {\n\t\tif sym, ok := symItem.(map[string]interface{}); ok {\n\t\t\tname, _ := sym[\"name\"].(string)\n\t\t\tstartLine, endLine := extractRange(sym)\n\t\t\tfunctions = append(functions, PythonFunctionSymbol{\n\t\t\t\tName:      name,\n\t\t\t\tStartLine: startLine,\n\t\t\t\tEndLine:   endLine,\n\t\t\t})\n\t\t}\n\t}\n\n\tfor i, line := range lines {\n\t\tif matches := reVar.FindStringSubmatch(line); matches != nil {\n\t\t\tvariables = append(variables, PythonVariableSymbol{\n\t\t\t\tName:          matches[1],\n\t\t\t\tDefinedAtLine: i + 1,\n\t\t\t})\n\t\t}\n\t}\n\n\treport := \u0026PythonAnalysisReport{\n\t\tFile:      filePath,\n\t\tFunctions: functions,\n\t\tVariables: variables,\n\t}\n\treport.File += \" (Python analyzed by LSP)\"\n\treturn report, nil\n}\n\nfunc AnalyzePythonFile(filePath string) (*PythonAnalysisReport, error) {\n\tcontent, err := os.ReadFile(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlines := regexp.MustCompile(\"\\r?\\n\").Split(string(content), -1)\n\treFunc := regexp.MustCompile(`^def\\s+(\\w+)\\s*\\(`)\n\treVar := regexp.MustCompile(`^(\\w+)\\s*=`)\n\tvar functions []PythonFunctionSymbol\n\tvar variables []PythonVariableSymbol\n\n\tfor i, line := range lines {\n\t\tif matches := reFunc.FindStringSubmatch(line); matches != nil {\n\t\t\tfunctions = append(functions, PythonFunctionSymbol{\n\t\t\t\tName:      matches[1],\n\t\t\t\tStartLine: i + 1,\n\t\t\t\tEndLine:   i + 1, // placeholder\n\t\t\t})\n\t\t}\n\t\tif matches := reVar.FindStringSubmatch(line); matches != nil {\n\t\t\tvariables = append(variables, PythonVariableSymbol{\n\t\t\t\tName:          matches[1],\n\t\t\t\tDefinedAtLine: i + 1,\n\t\t\t})\n\t\t}\n\t}\n\n\treport := \u0026PythonAnalysisReport{\n\t\tFile:      filePath,\n\t\tFunctions: functions,\n\t\tVariables: variables,\n\t}\n\treturn report, nil\n}\n\n// SavePyAnalysisReports writes the Python analysis reports to a JSON file.\nfunc SavePyAnalysisReports(reports []PythonAnalysisReport, outputPath string) error {\n\tdata, err := json.MarshalIndent(reports, \"\", \"  \")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn os.WriteFile(outputPath, data, 0644)\n}\n",
      "dependencies": [
        "context",
        "encoding/json",
        "log",
        "os",
        "time",
        "github.com/sourcegraph/jsonrpc2"
      ]
    },
    {
      "id": 8,
      "name": "go_mod_scanner.go",
      "category": "file",
      "path": "cgitrepo/goservice/go_mod_scanner.go",
      "content": "package main\n\nimport (\n    \"bufio\"\n    \"os\"\n    \"regexp\"\n    \"strings\"\n)\n\n// ScanGoMod reads a go.mod file and returns a list of module dependencies.\nfunc ScanGoMod(modFilePath string) ([]string, error) {\n    file, err := os.Open(modFilePath)\n    if err != nil {\n        return nil, err\n    }\n    defer file.Close()\n\n    depMap := make(map[string]bool)\n    scanner := bufio.NewScanner(file)\n\n    // Regular expressions to match require lines.\n    requireRegex := regexp.MustCompile(`^require\\s+(?:\\()?([^ \\t\\n]+)`)\n    blockLineRegex := regexp.MustCompile(`^([^ \\t\\n]+)\\s+`)\n\n    inRequireBlock := false\n    for scanner.Scan() {\n        line := strings.TrimSpace(scanner.Text())\n        if strings.HasPrefix(line, \"require (\") {\n            inRequireBlock = true\n            continue\n        }\n        if inRequireBlock {\n            if line == \")\" {\n                inRequireBlock = false\n                continue\n            }\n            if matches := blockLineRegex.FindStringSubmatch(line); len(matches) \u003e 1 {\n                depMap[matches[1]] = true\n            }\n        } else {\n            if strings.HasPrefix(line, \"require\") {\n                if matches := requireRegex.FindStringSubmatch(line); len(matches) \u003e 1 {\n                    depMap[matches[1]] = true\n                }\n            }\n        }\n    }\n\n    if err := scanner.Err(); err != nil {\n        return nil, err\n    }\n\n    var deps []string\n    for dep := range depMap {\n        deps = append(deps, dep)\n    }\n    return deps, nil\n}",
      "dependencies": [
        "strings",
        "bufio",
        "os"
      ]
    },
    {
      "id": 9,
      "name": "go_scanner.go",
      "category": "file",
      "path": "cgitrepo/goservice/go_scanner.go",
      "content": "package main\n\nimport (\n    \"os\"\n    \"regexp\"\n)\n\n// ScanGoScanner scans a Go file for import statements with improved parsing.\nfunc ScanGoScanner(filePath string) ([]string, error) {\n    content, err := os.ReadFile(filePath)\n    if err != nil {\n        return nil, err\n    }\n    text := string(content)\n    depMap := make(map[string]bool)\n\n    // Pattern for single-line imports: import \"package\" or alias \"package\"\n    singleImportRegex := regexp.MustCompile(`import\\s+(?:\\S+\\s+)?\\\"([^\\\"]+)\\\"`)\n    matches1 := singleImportRegex.FindAllStringSubmatch(text, -1)\n    for _, match := range matches1 {\n        if match[1] != \"\" {\n            depMap[match[1]] = true\n        }\n    }\n\n    // Pattern for grouped imports: import ( ... )\n    groupImportRegex := regexp.MustCompile(`import\\s+\\(([\\s\\S]*?)\\)`)\n    matches2 := groupImportRegex.FindAllStringSubmatch(text, -1)\n    for _, m := range matches2 {\n        groupText := m[1]\n        // Each line may have an alias and a quoted package.\n        lineRegex := regexp.MustCompile(`(?:\\S+\\s+)?\\\"([^\\\"]+)\\\"`)\n        lineMatches := lineRegex.FindAllStringSubmatch(groupText, -1)\n        for _, lm := range lineMatches {\n            if lm[1] != \"\" {\n                depMap[lm[1]] = true\n            }\n        }\n    }\n\n    var deps []string\n    for dep := range depMap {\n        deps = append(deps, dep)\n    }\n    return deps, nil\n}",
      "dependencies": [
        "os",
        "package",
        "regexp"
      ]
    },
    {
      "id": 10,
      "name": "graph_builder.go",
      "category": "file",
      "path": "cgitrepo/goservice/graph_builder.go",
      "content": "package main\n\nimport (\n\t\"encoding/json\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n)\n\n// Node represents a node in the dependency graph.\ntype Node struct {\n\tID           int      `json:\"id\"`\n\tName         string   `json:\"name\"`\n\tCategory     string   `json:\"category\"`\n\tPath         string   `json:\"path,omitempty\"`\n\tColor        string   `json:\"color,omitempty\"`\n\tContent      string   `json:\"content,omitempty\"`\n\tDependencies []string `json:\"dependencies,omitempty\"`\n}\n\n// Link represents an edge between two nodes.\ntype Link struct {\n\tSource   int     `json:\"source\"`\n\tTarget   int     `json:\"target\"`\n\tRelation string  `json:\"relation\"`\n\tStrength float64 `json:\"strength,omitempty\"`\n}\n\n// GraphData holds all nodes and links.\ntype GraphData struct {\n\tNodes    []Node `json:\"nodes\"`\n\tLinks    []Link `json:\"links\"`\n\tLanguage string `json:\"language\"`\n}\n\n\n// BuildGraph constructs a graph from the dependency tree, package dependencies, and Prisma schema.\nfunc BuildGraph(depTree map[string][]string, pkgDeps map[string]bool, mainLanguage string, prismaSchema *PrismaSchema) (GraphData, error) {\n\tvar graph GraphData\n\tfileNodeIDs := make(map[string]int)\n\tdepNodeIDs := make(map[string]int)\n\tidCounter := 0\n\n\t// Set the primary language\n\tgraph.Language = mainLanguage\n\n\t// Create a node for every file.\n\tfor file, deps := range depTree {\n\t\t// Read file content\n\t\tcontent, err := os.ReadFile(file)\n\t\tvar fileContent string\n\t\tif err == nil {\n\t\t\tfileContent = string(content)\n\t\t}\n\n\t\tnode := Node{\n\t\t\tID:           idCounter,\n\t\t\tName:         filepath.Base(file),\n\t\t\tCategory:     \"file\",\n\t\t\tPath:         file,\n\t\t\tContent:      fileContent,\n\t\t\tDependencies: deps,\n\t\t}\n\t\tgraph.Nodes = append(graph.Nodes, node)\n\t\tfileNodeIDs[file] = idCounter\n\t\tidCounter++\n\t}\n\n\t// Create nodes for dependencies.\n\tfor _, deps := range depTree {\n\t\tfor _, dep := range deps {\n\t\t\tif _, exists := depNodeIDs[dep]; !exists {\n\t\t\t\tcategory := \"dependency\"\n\t\t\t\tif pkgDeps != nil \u0026\u0026 pkgDeps[dep] {\n\t\t\t\t\tcategory = \"library\"\n\t\t\t\t}\n\t\t\t\tnode := Node{\n\t\t\t\t\tID:       idCounter,\n\t\t\t\t\tName:     dep,\n\t\t\t\t\tCategory: category,\n\t\t\t\t}\n\t\t\t\tgraph.Nodes = append(graph.Nodes, node)\n\t\t\t\tdepNodeIDs[dep] = idCounter\n\t\t\t\tidCounter++\n\t\t\t}\n\t\t}\n\t}\n\n\t// Create links from file nodes to dependency nodes.\n\tfor file, deps := range depTree {\n\t\tsrcID := fileNodeIDs[file]\n\t\tfor _, dep := range deps {\n\t\t\ttargetID, ok := depNodeIDs[dep]\n\t\t\tif !ok {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tlink := Link{\n\t\t\t\tSource:   srcID,\n\t\t\t\tTarget:   targetID,\n\t\t\t\tRelation: \"depends\",\n\t\t\t}\n\t\t\tgraph.Links = append(graph.Links, link)\n\t\t}\n\t}\n\n\t// Add Prisma schema information if available\n\tif prismaSchema != nil {\n\t\t// Create a node for the schema file itself\n\t\tschemaNodeID := idCounter\n\t\tschemaNode := Node{\n\t\t\tID:       schemaNodeID,\n\t\t\tName:     filepath.Base(prismaSchema.FilePath),\n\t\t\tCategory: \"prisma_schema\",\n\t\t\tPath:     prismaSchema.FilePath,\n\t\t\tColor:    \"#5a67d8\", // Use a distinctive color for Prisma\n\t\t}\n\t\tgraph.Nodes = append(graph.Nodes, schemaNode)\n\t\tidCounter++\n\n\t\t// Create nodes for each model in the schema\n\t\tfor _, model := range prismaSchema.Models {\n\t\t\tmodelNodeID := idCounter\n\t\t\tmodelNode := Node{\n\t\t\t\tID:       modelNodeID,\n\t\t\t\tName:     model.Name,\n\t\t\t\tCategory: \"prisma_model\",\n\t\t\t\tColor:    \"#4c51bf\",\n\t\t\t\tContent:  formatModelFields(model.Fields),\n\t\t\t}\n\t\t\tgraph.Nodes = append(graph.Nodes, modelNode)\n\t\t\tidCounter++\n\n\t\t\t// Link schema to model\n\t\t\tschemaToModelLink := Link{\n\t\t\t\tSource:   schemaNodeID,\n\t\t\t\tTarget:   modelNodeID,\n\t\t\t\tRelation: \"defines\",\n\t\t\t\tStrength: 1.0,\n\t\t\t}\n\t\t\tgraph.Links = append(graph.Links, schemaToModelLink)\n\t\t}\n\t}\n\n\treturn graph, nil\n}\n\n// Helper function to format model fields for display\nfunc formatModelFields(fields map[string]string) string {\n\tif len(fields) == 0 {\n\t\treturn \"\"\n\t}\n\n\tvar result strings.Builder\n\tfor name, fieldType := range fields {\n\t\tresult.WriteString(name)\n\t\tresult.WriteString(\": \")\n\t\tresult.WriteString(fieldType)\n\t\tresult.WriteString(\"\\n\")\n\t}\n\treturn result.String()\n}\n\n// SaveGraphData writes the graph JSON to a file.\nfunc SaveGraphData(filename string, graph GraphData) error {\n\tjsonData, err := json.MarshalIndent(graph, \"\", \"  \")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn os.WriteFile(filename, jsonData, 0644)\n}\n",
      "dependencies": [
        "encoding/json",
        "os",
        "strings"
      ]
    },
    {
      "id": 11,
      "name": "javascript_scanner.go",
      "category": "file",
      "path": "cgitrepo/goservice/javascript_scanner.go",
      "content": "package main\n\nimport (\n    \"os\"\n    \"regexp\"\n    \"strings\"\n)\n\n// ScanJSScanner scans a JavaScript/TypeScript/JSX/TSX file for dependency strings.\nfunc ScanJSScanner(filePath string) ([]string, error) {\n    content, err := os.ReadFile(filePath)\n    if err != nil {\n        return nil, err\n    }\n    text := string(content)\n\n    // Match import statements.\n\treImportFrom := regexp.MustCompile(`(?m)import\\s+.*?\\s+from\\s+['\"]([^'\"]+)['\"]`)\n\treImportType := regexp.MustCompile(`(?m)import\\s+type.*?\\s+from\\s+['\"]([^'\"]+)['\"]`)\n\treImportOnly := regexp.MustCompile(`(?m)import\\s+['\"]([^'\"]+)['\"]`)\n\treRequire := regexp.MustCompile(`(?m)require\\(\\s*['\"]([^'\"]+)['\"]\\s*\\)`)\n\t// Also capture static asset references like mp3, png, etc.\n\treAsset := regexp.MustCompile(`(?m)['\"]([^'\"]+\\.(?:mp3|png|jpg|jpeg|svg|gif))['\"]`)\n\t\n    depMap := make(map[string]bool)\n    extractDep := func(matches [][]string) {\n        for _, m := range matches {\n            dep := m[1]\n            // Skip relative imports.\n            if !strings.HasPrefix(dep, \".\") {\n                depMap[dep] = true\n            }\n        }\n    }\n\n    extractDep(reImportFrom.FindAllStringSubmatch(text, -1))\n    extractDep(reImportOnly.FindAllStringSubmatch(text, -1))\n    extractDep(reRequire.FindAllStringSubmatch(text, -1))\n    extractDep(reAsset.FindAllStringSubmatch(text, -1))\n\textractDep(reImportType.FindAllStringSubmatch(text, -1))\n\n    var deps []string\n    for dep := range depMap {\n        deps = append(deps, dep)\n    }\n    return deps, nil\n}",
      "dependencies": [
        "os",
        "regexp",
        "strings"
      ]
    },
    {
      "id": 12,
      "name": "lang_import_export.go",
      "category": "file",
      "path": "cgitrepo/goservice/lang_import_export.go",
      "content": "package main\n\nimport \"fmt\"\n\n// CheckImportsExports is a stub for language-specific validations.\nfunc CheckImportsExports(filePath string, language string) {\n    // This function can be expanded to check export/import correctness.\n    fmt.Printf(\"Checking import/export for language %s in %s\\n\", language, filePath)\n}",
      "dependencies": [
        "fmt"
      ]
    },
    {
      "id": 13,
      "name": "encoding/json",
      "category": "dependency"
    },
    {
      "id": 14,
      "name": "log",
      "category": "dependency"
    },
    {
      "id": 15,
      "name": "os",
      "category": "dependency"
    },
    {
      "id": 16,
      "name": "regexp",
      "category": "dependency"
    },
    {
      "id": 17,
      "name": "time",
      "category": "dependency"
    },
    {
      "id": 18,
      "name": "github.com/sourcegraph/jsonrpc2",
      "category": "dependency"
    },
    {
      "id": 19,
      "name": "context",
      "category": "dependency"
    },
    {
      "id": 20,
      "name": "path/filepath",
      "category": "dependency"
    },
    {
      "id": 21,
      "name": "fmt",
      "category": "dependency"
    },
    {
      "id": 22,
      "name": "bufio",
      "category": "dependency"
    },
    {
      "id": 23,
      "name": "strings",
      "category": "dependency"
    },
    {
      "id": 24,
      "name": "errors",
      "category": "dependency"
    },
    {
      "id": 25,
      "name": "io/fs",
      "category": "dependency"
    },
    {
      "id": 26,
      "name": "package",
      "category": "dependency"
    }
  ],
  "links": [
    {
      "source": 8,
      "target": 23,
      "relation": "depends"
    },
    {
      "source": 8,
      "target": 22,
      "relation": "depends"
    },
    {
      "source": 8,
      "target": 15,
      "relation": "depends"
    },
    {
      "source": 9,
      "target": 15,
      "relation": "depends"
    },
    {
      "source": 9,
      "target": 26,
      "relation": "depends"
    },
    {
      "source": 9,
      "target": 16,
      "relation": "depends"
    },
    {
      "source": 10,
      "target": 13,
      "relation": "depends"
    },
    {
      "source": 10,
      "target": 15,
      "relation": "depends"
    },
    {
      "source": 10,
      "target": 23,
      "relation": "depends"
    },
    {
      "source": 11,
      "target": 15,
      "relation": "depends"
    },
    {
      "source": 11,
      "target": 16,
      "relation": "depends"
    },
    {
      "source": 11,
      "target": 23,
      "relation": "depends"
    },
    {
      "source": 12,
      "target": 21,
      "relation": "depends"
    },
    {
      "source": 0,
      "target": 13,
      "relation": "depends"
    },
    {
      "source": 0,
      "target": 14,
      "relation": "depends"
    },
    {
      "source": 0,
      "target": 15,
      "relation": "depends"
    },
    {
      "source": 0,
      "target": 16,
      "relation": "depends"
    },
    {
      "source": 0,
      "target": 17,
      "relation": "depends"
    },
    {
      "source": 0,
      "target": 18,
      "relation": "depends"
    },
    {
      "source": 0,
      "target": 19,
      "relation": "depends"
    },
    {
      "source": 1,
      "target": 20,
      "relation": "depends"
    },
    {
      "source": 1,
      "target": 21,
      "relation": "depends"
    },
    {
      "source": 1,
      "target": 14,
      "relation": "depends"
    },
    {
      "source": 2,
      "target": 13,
      "relation": "depends"
    },
    {
      "source": 2,
      "target": 15,
      "relation": "depends"
    },
    {
      "source": 2,
      "target": 20,
      "relation": "depends"
    },
    {
      "source": 3,
      "target": 22,
      "relation": "depends"
    },
    {
      "source": 3,
      "target": 15,
      "relation": "depends"
    },
    {
      "source": 3,
      "target": 23,
      "relation": "depends"
    },
    {
      "source": 4,
      "target": 15,
      "relation": "depends"
    },
    {
      "source": 4,
      "target": 16,
      "relation": "depends"
    },
    {
      "source": 5,
      "target": 20,
      "relation": "depends"
    },
    {
      "source": 5,
      "target": 24,
      "relation": "depends"
    },
    {
      "source": 6,
      "target": 25,
      "relation": "depends"
    },
    {
      "source": 6,
      "target": 20,
      "relation": "depends"
    },
    {
      "source": 6,
      "target": 23,
      "relation": "depends"
    },
    {
      "source": 7,
      "target": 19,
      "relation": "depends"
    },
    {
      "source": 7,
      "target": 13,
      "relation": "depends"
    },
    {
      "source": 7,
      "target": 14,
      "relation": "depends"
    },
    {
      "source": 7,
      "target": 15,
      "relation": "depends"
    },
    {
      "source": 7,
      "target": 17,
      "relation": "depends"
    },
    {
      "source": 7,
      "target": 18,
      "relation": "depends"
    }
  ],
  "language": "go"
}